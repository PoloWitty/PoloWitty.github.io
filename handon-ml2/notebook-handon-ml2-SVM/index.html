<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Muse","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="Support Vector Machines support vector is any instance located on the &amp;#x201C;street&amp;#x201D;, including its border. The decision boundary is entirely determined by the support vectors. Any instance th">
<meta property="og:type" content="article">
<meta property="og:title" content="SVM">
<meta property="og:url" content="http://example.com/handon-ml2/notebook-handon-ml2-SVM/index.html">
<meta property="og:site_name" content="Paolo">
<meta property="og:description" content="Support Vector Machines support vector is any instance located on the &amp;#x201C;street&amp;#x201D;, including its border. The decision boundary is entirely determined by the support vectors. Any instance th">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2021-04-24T15:44:17.000Z">
<meta property="article:modified_time" content="2021-04-24T15:51:47.467Z">
<meta property="article:author" content="PaoloWitty">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://example.com/handon-ml2/notebook-handon-ml2-SVM/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>SVM | Paolo</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Paolo</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/handon-ml2/notebook-handon-ml2-SVM/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="PaoloWitty">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Paolo">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          SVM
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2021-04-24 23:44:17 / 修改时间：23:51:47" itemprop="dateCreated datePublished" datetime="2021-04-24T23:44:17+08:00">2021-04-24</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/handon-ml2/" itemprop="url" rel="index"><span itemprop="name">handon-ml2</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h1 id="Support-Vector-Machines"><a href="#Support-Vector-Machines" class="headerlink" title="Support Vector Machines"></a>Support Vector Machines</h1><blockquote>
<p><strong>support vector</strong> is any instance located on the &#x201C;street&#x201D;, including its border. The decision boundary is entirely determined by the support vectors. Any instance that is not a support vector has no influence whatsoever. Computing the predictions only involves the support vectors, not the whole training set.</p>
</blockquote>
<span id="more"></span>
<h2 id="Linear-SVM-Classification"><a href="#Linear-SVM-Classification" class="headerlink" title="Linear SVM Classification"></a>Linear SVM Classification</h2><p>also called <em>large margin classification</em>.</p>
<p>It is <em><strong>sensitive</strong></em> to feature scaling.</p>
<h3 id="Soft-Margin-Classification"><a href="#Soft-Margin-Classification" class="headerlink" title="Soft Margin Classification"></a>Soft Margin Classification</h3><blockquote>
<p>If we strictly impose that all instances must be off the street( the decision boundary ) and on the right side, this is called <strong>hard margin classification</strong>.</p>
<p>Hard margin classification is <em><strong>sensitive</strong></em> to outliers.</p>
</blockquote>
<p>So the Soft Margin classification is to find a good balance between keeping the street as large as possible and limiting the <em>margin violations</em> (i.e., instances that end up in the middle of the street or even  on the wrong side)</p>
<p>the hyperparameter to make the balance is <em>C</em>, which just the same function as C in <em>Logistic Regression</em>. The only thing need to attention is that when SVM overfit the dataset, the street is small and the margin violation is small. </p>
<p>prepare the data:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">iris=datasets.load_iris()</span><br><span class="line">X=iris[<span class="string">&apos;data&apos;</span>][:,(<span class="number">2</span>,<span class="number">3</span>)]</span><br><span class="line">y=(iris[<span class="string">&apos;target&apos;</span>]==<span class="number">2</span>).astype(np.float64)</span><br></pre></td></tr></table></figure>

<p>there many ways to perform Linear SVM:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.pipeline <span class="keyword">import</span> Pipeline</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> LinearSVC</span><br><span class="line"></span><br><span class="line">svm_clf=Pipeline([</span><br><span class="line">    (<span class="string">&apos;scaler&apos;</span>,StandardScaler()),<span class="comment">#The *LinearSVC* class regularizes the bias term, so you should center the training set first by subtracting its mean, which will be automatic done by StandardScaler</span></span><br><span class="line">    (<span class="string">&apos;linear_svc&apos;</span>,LinearSVC(C=<span class="number">1</span>,loss=<span class="string">&apos;hinge&apos;</span>))<span class="comment">#the loss=&apos;hinge&apos; is essential since it&apos;s not the default value</span></span><br><span class="line">])</span><br><span class="line">svm_clf.fit(X,y)</span><br></pre></td></tr></table></figure>

<p>For better performance, you should set the <em>dual</em> hyperparameter of <em>LinearSVC</em> to False, unless there are more features than training instances. Remember, the <em>LinearSVC</em> implements an optimized  algorithm for linear SVMs. It does not support the kernel trick, but it scales almost linearly with the number of training instances and the number of features. </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> SVC</span><br><span class="line">svm_clf=SVC(kernel=<span class="string">&apos;linear&apos;</span>,C=<span class="number">1</span>)</span><br><span class="line">svm_clf.fit(X,y)</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> SGDClassifier</span><br><span class="line">m=<span class="number">1</span>;C=<span class="number">1</span></span><br><span class="line">svm_clf=SGDClassifier(loss=<span class="string">&apos;hinge&apos;</span>,alpha=<span class="number">1</span>/(m*C))</span><br></pre></td></tr></table></figure>

<h2 id="Nonlinear-SVM-Classification"><a href="#Nonlinear-SVM-Classification" class="headerlink" title="Nonlinear SVM Classification"></a>Nonlinear SVM Classification</h2><p>there are many ways to handle nonlinear classification using SVM</p>
<h3 id="make-the-features-linearly-separable"><a href="#make-the-features-linearly-separable" class="headerlink" title="make the features linearly separable"></a>make the features linearly separable</h3><h4 id="Polynomial-Features-method"><a href="#Polynomial-Features-method" class="headerlink" title="Polynomial Features method"></a>Polynomial Features method</h4><p>just the same as the linear regression</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.pipeline <span class="keyword">import</span> Pipeline</span><br><span class="line">polynomial_svm_clf=Pipeline([</span><br><span class="line">    (<span class="string">&apos;poly_features&apos;</span>,PolynomialFeatures(degree=<span class="number">3</span>)),</span><br><span class="line">    (<span class="string">&apos;scaler&apos;</span>,StandardScaler()),</span><br><span class="line">    (<span class="string">&apos;svm_clf&apos;</span>,LinearSVC(C=<span class="number">10</span>,loss=<span class="string">&apos;hinge&apos;</span>))</span><br><span class="line">])</span><br></pre></td></tr></table></figure>

<h4 id="Similarity-Features-method"><a href="#Similarity-Features-method" class="headerlink" title="Similarity Features method"></a>Similarity Features method</h4><p>Similarity function measures how much each instance resembles a particular landmark. It can be Gaussian Radial Basis Function(RBF):<br>$$<br>\phi_\gamma(\mathbf x,l)=exp(-\gamma||\mathbf x -l||^2)<br>$$<br>$l$ is the chosen landmark.</p>
<p>The simplest approach is to create a landmark at the location of each and every instance in the dataset. Doing that creates many dimensions and thus increases the chances that the transformed training set will be linearly separable. The downside is that a training set with <strong>m</strong> instances and <strong>n</strong> features gets transformed into a training set with <strong>m</strong> instances and <strong>m</strong> features(have dropped the original features). </p>
<p>These two methods can both be useful with any Machine Learning algorithm, but it may be computationally expensive to compute all the additional features, especially on large training sets.</p>
<h3 id="Kernel-trick"><a href="#Kernel-trick" class="headerlink" title="Kernel trick"></a>Kernel trick</h3><h4 id="Polynomial-Kernel"><a href="#Polynomial-Kernel" class="headerlink" title="Polynomial Kernel"></a>Polynomial Kernel</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> SVC</span><br><span class="line">poly_kernel_svm_clf=Pipeline([</span><br><span class="line">    (<span class="string">&apos;scaler&apos;</span>,StandardScaler()),</span><br><span class="line">    (<span class="string">&apos;svm_clf&apos;</span>,SVC(kernel=<span class="string">&apos;poly&apos;</span>,degree=<span class="number">3</span>,coef0=<span class="number">1</span>,C=<span class="number">5</span>))</span><br><span class="line">])</span><br></pre></td></tr></table></figure>

<p>The <em>coef0</em> controls how much the model is influenced by high-degree polynomials versus low-degree polynomials.</p>
<h4 id="Gaussian-RBF-Kernel"><a href="#Gaussian-RBF-Kernel" class="headerlink" title="Gaussian RBF Kernel"></a>Gaussian RBF Kernel</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">rbf_kernel_svm_clf=Pipeline([</span><br><span class="line">    (<span class="string">&apos;scaler&apos;</span>,StandardScaler()),</span><br><span class="line">    (<span class="string">&apos;svm_clf&apos;</span>,SVC(kernel=<span class="string">&apos;rbf&apos;</span>,gamma=<span class="number">5</span>,C=<span class="number">0.001</span>))</span><br><span class="line">])</span><br></pre></td></tr></table></figure>

<p>the $\gamma$ acts like a regularization hyperparameter( bigger $\gamma$ , bigger penalty )</p>
<h4 id="choice-among-different-kernels"><a href="#choice-among-different-kernels" class="headerlink" title="choice among different kernels"></a>choice among different kernels</h4><p>As a rule of thumb, you should always try the linear kernel first(<em>LinearSVC</em> is much faster than <em>SVC(kernel=&#x2019;linear&#x2019;)</em>, but <em>LinearSVC</em> does not support the kernel trick ), especially if the training set is very large or if it has plenty of features.</p>
<p>If the training set is not too large, you should also try Gaussian RBF kernel, it works well in most cases.  </p>
<h2 id="SVM-Regression"><a href="#SVM-Regression" class="headerlink" title="SVM Regression"></a>SVM Regression</h2><h3 id="difference-to-SVM-classification"><a href="#difference-to-SVM-classification" class="headerlink" title="difference to SVM classification"></a>difference to SVM classification</h3><p>To use SVMs for regression instead of classification, the trick is to reverse the objective: instead of trying to fit the largest possible street between two classes while limiting margin violations, SVM Regression tries to fit as many instances as possible <strong>on</strong> the street while limiting margin violations ( i.e., instances <strong>off</strong> the street )</p>
<p>The width of the street is controlled by hyperparameter $\varepsilon$ , bigger $\varepsilon$ , larger margin. But SVM Regression is <strong>$\mathbf\varepsilon$-insensitive</strong> ( adding more training instances within the margin does not affect the model&#x2019;s predictions)</p>
<h3 id="Linear-Regression"><a href="#Linear-Regression" class="headerlink" title="Linear Regression"></a>Linear Regression</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> LinearSVR</span><br><span class="line">svm_reg=LinearSVR(epsilon=<span class="number">1</span>)</span><br><span class="line">svm_reg.fit(X,y)</span><br></pre></td></tr></table></figure>

<h3 id="Nonlinear-Regression"><a href="#Nonlinear-Regression" class="headerlink" title="Nonlinear Regression"></a>Nonlinear Regression</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> SVR</span><br><span class="line">svm_poly_reg=SVR(kernel=<span class="string">&apos;poly&apos;</span>,degree=<span class="number">2</span>,C=<span class="number">50</span>,epsilon=<span class="number">0.1</span>)</span><br><span class="line">svm_poly_reg.fit(X,y)</span><br></pre></td></tr></table></figure>


    </div>

    
    
    

      <footer class="post-footer">

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/handon-ml2/notebook-handon-ml2-%E5%B8%B8%E8%A7%84%E6%93%8D%E4%BD%9C/" rel="prev" title="一些常规操作">
      <i class="fa fa-chevron-left"></i> 一些常规操作
    </a></div>
      <div class="post-nav-item">
    <a href="/handon-ml2/notebook-handon-ml2-Regression/" rel="next" title="Regression">
      Regression <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Support-Vector-Machines"><span class="nav-number">1.</span> <span class="nav-text">Support Vector Machines</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Linear-SVM-Classification"><span class="nav-number">1.1.</span> <span class="nav-text">Linear SVM Classification</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Soft-Margin-Classification"><span class="nav-number">1.1.1.</span> <span class="nav-text">Soft Margin Classification</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Nonlinear-SVM-Classification"><span class="nav-number">1.2.</span> <span class="nav-text">Nonlinear SVM Classification</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#make-the-features-linearly-separable"><span class="nav-number">1.2.1.</span> <span class="nav-text">make the features linearly separable</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Polynomial-Features-method"><span class="nav-number">1.2.1.1.</span> <span class="nav-text">Polynomial Features method</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Similarity-Features-method"><span class="nav-number">1.2.1.2.</span> <span class="nav-text">Similarity Features method</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Kernel-trick"><span class="nav-number">1.2.2.</span> <span class="nav-text">Kernel trick</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Polynomial-Kernel"><span class="nav-number">1.2.2.1.</span> <span class="nav-text">Polynomial Kernel</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Gaussian-RBF-Kernel"><span class="nav-number">1.2.2.2.</span> <span class="nav-text">Gaussian RBF Kernel</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#choice-among-different-kernels"><span class="nav-number">1.2.2.3.</span> <span class="nav-text">choice among different kernels</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#SVM-Regression"><span class="nav-number">1.3.</span> <span class="nav-text">SVM Regression</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#difference-to-SVM-classification"><span class="nav-number">1.3.1.</span> <span class="nav-text">difference to SVM classification</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Linear-Regression"><span class="nav-number">1.3.2.</span> <span class="nav-text">Linear Regression</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Nonlinear-Regression"><span class="nav-number">1.3.3.</span> <span class="nav-text">Nonlinear Regression</span></a></li></ol></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">PaoloWitty</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives">
          <span class="site-state-item-count">12</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">3</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">2</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">PaoloWitty</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://muse.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a> 强力驱动
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  

  

</body>
</html>
